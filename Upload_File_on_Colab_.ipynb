{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNaevv12rCyTqbn4vxWizO5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NIKKISAHA/machineLearning/blob/main/Upload_File_on_Colab_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_UCIhcdNfcv"
      },
      "outputs": [],
      "source": [
        "# how to read a file on google colab, we cannot upload files on google colab , we have to upload it using zip or file compressed\n",
        "\n",
        "import pandas as pd\n",
        "path = pd.read_csv(\"features_30_sec.csv\")\n",
        "# \"features_30_sec.csv\" - replace this with file name and make sure that you have uploaded the file on google colab\n",
        "\n",
        "#load from kares build in\n",
        "from tensorflow.keras.datasets import imdb\n",
        "(num_train_samples), (num_test_samples) = imdb.load_data(num_words=10000)\n",
        "\n",
        "# another example\n",
        "from keras.datasets import mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# another example\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Extract the lfw-funneled.tgz file\n",
        "!tar -xvf lfw-funneled.tgz\n",
        "!file lfw-funneled.tgz\n",
        "!ls -lh lfw-funneled.tgz\n",
        "\n",
        "# Extract the zip file\n",
        "!unzip -q /content/archive.zip -d /content/\n",
        "!file archive.zip\n",
        "!ls -lh archive.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "---- quesyion - I have downloaded the code in the path Path to dataset files: /root/.cache/kagglehub/datasets/jessicali9530/stanford-cars-dataset/versions/2\n",
        "on google colab\n",
        "Is it got downloaded on my system, where is it got downloaded ?\n",
        "\n",
        "ans : No!\n",
        "The files are not downloaded to your local system. They are stored in the Google Colab environment.\n",
        "\n",
        "If you want to download the files to your system:\n",
        "\n",
        "1. Go to the Google Colab file explorer.\n",
        "2. Right-click on the file/folder.\n",
        "3. Select \"Download\".\n",
        "\n",
        "Or, use the `!download` command in a Colab cell. Here's an example:\n",
        "\n",
        "You downloaded the Stanford Cars dataset to:\n",
        "\n",
        "`/root/.cache/kagglehub/datasets/jessicali9530/stanford-cars-dataset/versions/2`\n",
        "\n",
        "To download it to your local system:\n",
        "\n",
        "1. Open a new cell in Google Colab.\n",
        "2. Type: `!download /root/.cache/kagglehub/datasets/jessicali9530/stanford-cars-dataset/versions/2`\n",
        "3. Press Shift+Enter.\n",
        "\n",
        "The file will be downloaded to your local system!"
      ],
      "metadata": {
        "id": "UXanNJdqxGy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------pre trained model---------\n",
        "\n",
        "# Import necessary libraries\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "# base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
        "\n",
        "# Freeze the early layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add custom layers\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dense(10, activation='sigmoid')(x)\n",
        "\n",
        "# Create the new model\n",
        "model = Model(inputs=base_model.input, outputs=x)"
      ],
      "metadata": {
        "id": "kVirN1NpyKBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for opening the file directly, if you want to open it directly cuz you have already uploaded it and know the file name\n",
        "from PIL import Image\n",
        "img = Image.open('number_1.png')\n",
        "\n",
        "#upload option will appear\n",
        "from google.colab import files\n",
        "imga = files.upload() #returns-dictionary,have to assain it to a veriable,in python whena function return value and you don't assain it you will get a warning\n",
        "file_content = list(imga.keys())[0] #save the last uploaded file\n",
        "img = file_content\n",
        "print(\"file is \", img)\n",
        "\n",
        "# then open it\n",
        "# for opening the file\n",
        "from PIL import Image\n",
        "img = Image.open(img) #open the image\n",
        "\n",
        "\n",
        "# For resixing\n",
        "import numpy as np\n",
        "img = img.resize((28, 28))\n",
        "img = img.convert('L')  # Convert to grayscale\n",
        "img = img.convert('RGB') # Convert to rgb\n",
        "img = np.array(img) / 255.0  # Normalize pixel values\n",
        "img = img.reshape((1, 28, 28, 1)) #Add a size\n",
        "img = np.expand_dims(img,axis=0) #batch dimension to the image\n",
        "\n",
        "\n",
        "# prediction\n",
        "prediction = model.predict(img)\n",
        "predicted_class = np.argmax(prediction)\n",
        "print(\"Predicted digit class:\", predicted_class)\n",
        "class_labels = [ 'T-shirt/top','Trouser','Pullover', 'Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle boot']\n",
        "predicted_class_index = np.argmax(prediction)\n",
        "predicted_class_label = class_labels[predicted_class_index]\n",
        "print('Predicted class:', predicted_class_label)\n",
        "\n",
        "--------- question - I have downloaded the code in the path Path to dataset files: /root/.cache/kagglehub/datasets/jessicali9530/stanford-cars-dataset/versions/2\n",
        "Then I did --\n",
        "Train_dir = os.path.join(path, 'cars_train')\n",
        "test_dir = os.path.join(path, 'cars_test')\n",
        "How to check if images are gray or rgb ?\n",
        "\n",
        "ans : Now that you have the train and test directories, you can check the image type using the following code:\n",
        "\n",
        "```\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "Your paths\n",
        "path = '/root/.cache/kagglehub/datasets/jessicali9530/stanford-cars-dataset/versions/2'\n",
        "train_dir = os.path.join(path, 'cars_train')\n",
        "test_dir = os.path.join(path, 'cars_test')\n",
        "\n",
        "Get the first image from the train directory\n",
        "img_path = os.path.join(train_dir, os.listdir(train_dir)[0])\n",
        "\n",
        "Read the image\n",
        "img = plt.imread(img_path)\n",
        "\n",
        "Print the image shape\n",
        "print(img.shape)\n",
        "```\n",
        "\n",
        "If the output is:\n",
        "\n",
        "- `(height, width, 3)`, the images are RGB.\n",
        "- `(height, width)`, the images are grayscale.\n",
        "\n",
        "Run this code to check the image type!"
      ],
      "metadata": {
        "id": "s52LXw6lQZm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# example 1\n",
        "data_gen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        ")\n",
        "\n",
        "model.fit(data_gen.flow(x_train, y_train, batch_size=64), epochs=15, validation_data=(x_test, y_test))\n",
        "\n",
        "# example 2 for directory - example file - face recognition\n",
        "dataset_dir = 'lfw_funneled' # directory path = lfw_funneled\n",
        "\n",
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    dataset_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=10\n",
        ")"
      ],
      "metadata": {
        "id": "kCgukvK0mCnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#basic structure of model for images\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(len(train_generator.class_indices), activation='softmax'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "#-----------------or this model--------------------\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "# model.add(Conv2D(256, (3, 3), activation='relu'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(MaxPooling2D((2, 2)))\n",
        "# model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "bnErygw7o7Ua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# two ways to add batch size\n",
        "history = model.fit(\n",
        "    ds_train.batch(32),  # Batch size for training\n",
        "    epochs=10,\n",
        "    validation_data=ds_test.batch(32),  # Batch size for testing\n",
        ")\n",
        "\n",
        "#or this ---------\n",
        "ds_train = ds_train.batch(32)\n",
        "ds_test = ds_test.batch(32)\n",
        "\n",
        "history = model.fit(\n",
        "    ds_train,\n",
        "    epochs=10,\n",
        "    validation_data=ds_test,\n",
        ")\n",
        "\n",
        "# or this\n",
        "data_gen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        ")\n",
        "\n",
        "model.fit(data_gen.flow(x_train, y_train, batch_size=64), epochs=15, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "id": "aOOp2Hwm64qO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------ for converting greyscale into rgb colors -----------\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "x_train = np.array([Image.fromarray(img).resize((32, 32)) for img in x_train])\n",
        "x_test = np.array([Image.fromarray(img).resize((32, 32)) for img in x_test])\n",
        "\n",
        "# Repeat grayscale channel to create pseudo-RGB images\n",
        "x_train = np.repeat(x_train[..., np.newaxis], 3, axis=3)\n",
        "x_test = np.repeat(x_test[..., np.newaxis], 3, axis=3)\n",
        "\n",
        "# Normalize pixel values\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255"
      ],
      "metadata": {
        "id": "nf2gvmZV0aeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "for converting greyscale into rgb colors"
      ],
      "metadata": {
        "id": "bw75XQDgPrQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------  it is a must for the images to reshape and normalize it -----------------\n",
        "\n",
        "# Reshape and normalize images\n",
        "x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255\n",
        "x_test = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255"
      ],
      "metadata": {
        "id": "RKTnjf4y9Xkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "it is a must for the images to reshape and normalize it"
      ],
      "metadata": {
        "id": "mRLilUemOkQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------  python codefpr converting pixel values to images  -----------------\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "# assuming 'pixels' is a string of space-separated pixel values\n",
        "pixels = np.array(pixels.split(' ')).reshape(48, 48).astype('uint8')\n",
        "\n",
        "# create an image from the pixel values\n",
        "img = Image.fromarray(pixels)\n",
        "\n",
        "# save the image to a file\n",
        "img.save('image.png')"
      ],
      "metadata": {
        "id": "IAXjVzeGOg0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "python code for converting pixel values to images"
      ],
      "metadata": {
        "id": "5vs3uLHfPiPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/archive.zip -d /content/\n",
        "-!ls /content/\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define the paths to the train and test folders\n",
        "train_path = '/content/train'\n",
        "test_path = '/content/test'\n",
        "\n",
        "# Define the data generators\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Load training data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=(48, 48),\n",
        "    batch_size=32,\n",
        "    color_mode='grayscale',\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Load testing data\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_path,\n",
        "    target_size=(48, 48),\n",
        "    batch_size=32,\n",
        "    color_mode='grayscale',\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "id": "Z317zP6jnyha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "whenever you have a zip file or tar file and you extract in in colab use above code -last example we have a zip file called - archive.zip , then it has folders test and train"
      ],
      "metadata": {
        "id": "4QvPUr0AnzmL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"jessicali9530/stanford-cars-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "import kagglehub\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Load dataset\n",
        "train_dir = os.path.join(path, 'cars_train')\n",
        "test_dir = os.path.join(path, 'cars_test')\n",
        "\n",
        "# Load and preprocess data using Keras ImageDataGenerator\n",
        "train_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255,\n",
        "                                                                    shear_range=0.2,\n",
        "                                                                    zoom_range=0.2,\n",
        "                                                                    horizontal_flip=True)\n",
        "\n",
        "test_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                        target_size=(224, 224),\n",
        "                                                        batch_size=32,\n",
        "                                                        class_mode='categorical')\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(test_dir,\n",
        "                                                      target_size=(224, 224),\n",
        "                                                      batch_size=32,\n",
        "                                                      class_mode='categorical')"
      ],
      "metadata": {
        "id": "EkcgSuejeOhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "buddy listen , whenever you download something from kaggle directly using code code - use this method"
      ],
      "metadata": {
        "id": "MCY00v5HePcn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "------1. question - where to use sparse_categorical_crossentropy and categorical_crossentropy ?\n",
        "\n",
        "ans - While it's technically working, it's still not the most correct or efficient approach.\n",
        "Using sparse_categorical_crossentropy with one-hot encoded labels is a bit of a hack, relying on TensorFlow's internal conversion.\n",
        "\n",
        "For clarity, maintainability, and performance, it's still recommended to:\n",
        "\n",
        "- Use categorical_crossentropy with one-hot encoded labels.\n",
        "- Use sparse_categorical_crossentropy with integer labels.\n",
        "\n",
        "So, while it's working, I'd suggest switching to categorical_crossentropy for consistency and best practices.\n",
        "\n",
        "\n",
        "\n",
        "----------2. question - \"train_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255,\n",
        "                                                                    shear_range=0.2,\n",
        "                                                                    zoom_range=0.2,\n",
        "                                                                    horizontal_flip=True)\n",
        "test_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                        target_size=(224, 224),\n",
        "                                                        batch_size=32,\n",
        "                                                        class_mode='categorical')\n",
        "test_generator = test_datagen.flow_from_directory(test_dir,\n",
        "                                                      target_size=(224, 224),\n",
        "                                                      batch_size=32,\n",
        "                                                      class_mode='categorical') - which one is one hot encoding, how to check it\" ?\n",
        "ans - Run this code:\n",
        "batch_images, batch_labels = next(train_generator)\n",
        "print(\"Label shape:\", batch_labels.shape)\n",
        "\n",
        "2. Look at the output. It will show the shape of the labels.\n",
        "3. If the shape has TWO numbers, like (32, 196), then the labels are ONE-HOT ENCODED.\n",
        "\n",
        "Example output:\n",
        "Label shape: (32, 196)\n",
        "\n",
        "If you see TWO numbers, it means the labels are one-hot encoded!\n",
        "\n",
        "---------following question: Two numbers (32,196)? Shouldn't it be 0 and 1?\n",
        "ans- You're thinking of the actual values of the labels, but I was referring to the SHAPE of the labels.\n",
        "\n",
        "In one-hot encoding:\n",
        "\n",
        "- The shape has TWO numbers: (batch_size, num_classes)\n",
        "- The values are indeed 0s and 1s, but the shape tells us it's one-hot encoded.\n",
        "\n",
        "So:\n",
        "\n",
        "- (32, 196) means 32 samples, each with 196 classes (one-hot encoded)\n",
        "- The actual values would be 0s and 1s, like [0, 0, 1, 0, ...]\n",
        "\n",
        "---------following question:What if it's not a one hot encoded data\n",
        "Then how will it show\n",
        "ans - If the data is NOT one-hot encoded:\n",
        "\n",
        "- The shape will have ONLY ONE number: (batch_size,)\n",
        "- The values will be integer labels (e.g., 0, 1, 2, ...)\n",
        "\n",
        "Example:\n",
        "\n",
        "- Shape: (32,)\n",
        "- Values: [0, 1, 2, 0, 1, ...]\n",
        "\n",
        "This indicates that the data is using integer labels, not one-hot encoding.\n",
        "\n",
        "So, to summarize:\n",
        "\n",
        "- One-hot encoded: (batch_size, num_classes) with 0s and 1s\n",
        "- Integer labels: (batch_size,) with integer values\n",
        "\n",
        "Imp example - Buddy!\n",
        "\n",
        "Here's an example code:\n",
        "\n",
        "```\n",
        "import numpy as np\n",
        "\n",
        "One-hot encoded labels\n",
        "labels_one_hot = np.array([[0, 0, 1, 0],\n",
        "                              [0, 1, 0, 0],\n",
        "                              [1, 0, 0, 0]])\n",
        "\n",
        "Print shape\n",
        "print(\"Shape:\", labels_one_hot.shape)\n",
        "\n",
        "Print labels\n",
        "print(\"Labels:\")\n",
        "print(labels_one_hot)\n",
        "```\n",
        "\n",
        "Output:\n",
        "\n",
        "```\n",
        "Shape: (3, 4)\n",
        "Labels:\n",
        "[[0 0 1 0]\n",
        " [0 1 0 0]\n",
        " [1 0 0 0]]\n",
        "```\n",
        "\n",
        "In this example:\n",
        "\n",
        "- The shape is `(3, 4)`, which means there are 3 samples and 4 classes.\n",
        "- The labels are one-hot encoded, with only one `1` per row.\n",
        "\n",
        "Now, try this with your own labels, buddy!"
      ],
      "metadata": {
        "id": "L1Xvg3q2pVal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "------1. question - where to use sparse_categorical_crossentropy and categorical_crossentropy ?\n",
        "\n",
        "ans - While it's technically working, it's still not the most correct or efficient approach.\n",
        "Using sparse_categorical_crossentropy with one-hot encoded labels is a bit of a hack, relying on TensorFlow's internal conversion.\n",
        "\n",
        "For clarity, maintainability, and performance, it's still recommended to:\n",
        "\n",
        "- Use categorical_crossentropy with one-hot encoded labels.\n",
        "- Use sparse_categorical_crossentropy with integer labels.\n",
        "\n",
        "So, while it's working, I'd suggest switching to categorical_crossentropy for consistency and best practices.\n",
        "\n",
        "\n",
        "\n",
        "----------2. question - \"train_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255,\n",
        "                                                                    shear_range=0.2,\n",
        "                                                                    zoom_range=0.2,\n",
        "                                                                    horizontal_flip=True)\n",
        "test_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                        target_size=(224, 224),\n",
        "                                                        batch_size=32,\n",
        "                                                        class_mode='categorical')\n",
        "test_generator = test_datagen.flow_from_directory(test_dir,\n",
        "                                                      target_size=(224, 224),\n",
        "                                                      batch_size=32,\n",
        "                                                      class_mode='categorical') - which one is one hot encoding, how to check it\" ?\n",
        "ans - Run this code:\n",
        "batch_images, batch_labels = next(train_generator)\n",
        "print(\"Label shape:\", batch_labels.shape)\n",
        "\n",
        "2. Look at the output. It will show the shape of the labels.\n",
        "3. If the shape has TWO numbers, like (32, 196), then the labels are ONE-HOT ENCODED.\n",
        "\n",
        "Example output:\n",
        "Label shape: (32, 196)\n",
        "\n",
        "If you see TWO numbers, it means the labels are one-hot encoded!\n",
        "\n",
        "---------following question: Two numbers (32,196)? Shouldn't it be 0 and 1?\n",
        "ans- You're thinking of the actual values of the labels, but I was referring to the SHAPE of the labels.\n",
        "\n",
        "In one-hot encoding:\n",
        "\n",
        "- The shape has TWO numbers: (batch_size, num_classes)\n",
        "- The values are indeed 0s and 1s, but the shape tells us it's one-hot encoded.\n",
        "\n",
        "So:\n",
        "\n",
        "- (32, 196) means 32 samples, each with 196 classes (one-hot encoded)\n",
        "- The actual values would be 0s and 1s, like [0, 0, 1, 0, ...]\n",
        "\n",
        "---------following question:What if it's not a one hot encoded data\n",
        "Then how will it show\n",
        "ans - If the data is NOT one-hot encoded:\n",
        "\n",
        "- The shape will have ONLY ONE number: (batch_size,)\n",
        "- The values will be integer labels (e.g., 0, 1, 2, ...)\n",
        "\n",
        "Example:\n",
        "\n",
        "- Shape: (32,)\n",
        "- Values: [0, 1, 2, 0, 1, ...]\n",
        "\n",
        "This indicates that the data is using integer labels, not one-hot encoding.\n",
        "\n",
        "So, to summarize:\n",
        "\n",
        "- One-hot encoded: (batch_size, num_classes) with 0s and 1s\n",
        "- Integer labels: (batch_size,) with integer values\n",
        "\n",
        "Imp example - Buddy!\n",
        "\n",
        "Here's an example code:\n",
        "\n",
        "```\n",
        "import numpy as np\n",
        "\n",
        "One-hot encoded labels\n",
        "labels_one_hot = np.array([[0, 0, 1, 0],\n",
        "                              [0, 1, 0, 0],\n",
        "                              [1, 0, 0, 0]])\n",
        "\n",
        "Print shape\n",
        "print(\"Shape:\", labels_one_hot.shape)\n",
        "\n",
        "Print labels\n",
        "print(\"Labels:\")\n",
        "print(labels_one_hot)\n",
        "```\n",
        "\n",
        "Output:\n",
        "\n",
        "```\n",
        "Shape: (3, 4)\n",
        "Labels:\n",
        "[[0 0 1 0]\n",
        " [0 1 0 0]\n",
        " [1 0 0 0]]\n",
        "```\n",
        "\n",
        "In this example:\n",
        "\n",
        "- The shape is `(3, 4)`, which means there are 3 samples and 4 classes.\n",
        "- The labels are one-hot encoded, with only one `1` per row.\n",
        "\n",
        "Now, try this with your own labels, buddy!"
      ],
      "metadata": {
        "id": "p0NAkYX2tMnD"
      }
    }
  ]
}